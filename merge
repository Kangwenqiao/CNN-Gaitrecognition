#evaluate_one.py
import numpy as np
import torch

from network import NetWork
from utils import cv_imread

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 显卡能用于深度学习，就会使用，用不了则自动使用CPU运行

n_class = 124  # 共几类
save_model_name = 'model.h5'  # 模型保存的名字


def evaluate(image_path=r'./GEI/001_nm-01_000.png'):
    image_path = image_path.replace('\\', '/')  # 反斜杠转为斜杠，可适用于linux系统
    image = cv_imread(image_path)[...,0]  # 读图
    image = image[np.newaxis, :, :, np.newaxis]  # 维度扩充为(b,h,w,c)
    image = np.transpose(image, axes=[0, 3, 1, 2]).astype('float32') / 255.  # 转置和归一化
    b, c, h, w = image.shape
    image_name = image_path.split('/')[-1]  # 001_nm-01_000.png
    label = int(image_name[0:3])
    # 加载网络
    model = NetWork(c, h, w, n_class).to(device)  # 加载网络(调用network.py文件里的network函数)
    # 测试网络
    model.load_state_dict(torch.load(save_model_name, map_location=device))  # 加载刚刚保存的权重给网络
    model.eval()
    # y_pred_prob = model(image)  # 预测，和上面val_accuracy其实是一样的
    y_pred_prob = model(torch.from_numpy(image).to(device))  # 预测 (b,n_class)
    y_pred_prob = torch.softmax(y_pred_prob.float(), dim=-1).float().cpu().detach().numpy()  # (b,n_class)
    y_true = label - 1  # 从0开始编号，到123，共124人
    y_pred = np.argmax(y_pred_prob, -1).item()  # 从0开始编号，到123，共124人
    acc = np.mean(np.equal(y_pred, y_true) * 100)
    print('真实标签:', y_true)
    print('预测标签:', y_pred)
    print('预测概率:', np.squeeze(y_pred_prob)[y_pred])
    # print('准确率:%f%%' % acc)
    return y_pred_prob, y_pred, y_true, acc


if __name__ == '__main__':
    evaluate()


#GUI.py
# -*- coding: utf-8 -*-
import os
import threading
import tkinter as tk
import tkinter.messagebox as msgbox
from tkinter import filedialog

import numpy as np
from PIL import ImageTk, Image

from evaluate_one import evaluate
from utils import show_image


# 按键调用函数：导入路径
def import_content_path():
    img_path = filedialog.askopenfilename()
    img_path = img_path.replace('\\', '/')  # 反斜杠转为斜杠，可适用于linux系统
    img_name = img_path.split('/')[-1]  # 001_nm-01_000.png
    content_path_val.set(img_path)

    pilImage = Image.open(img_path).resize((128, 128))  # 把图片放上去
    tkImage = ImageTk.PhotoImage(image=pilImage)
    label2.configure(image=tkImage)
    label2.image = tkImage  # 除非是面向对象的写法，否则一定要加上这一句！不然界面是显示全白色图片的
    y_true = int(img_name[0:img_name.find('_')]) - 1  # 第0个label表示第1个人
    label3.configure(text='真实标签:')
    label3_num.configure(text=str(y_true))
    probLabel.configure(text='')
    numLabel.configure(text='')


# 按键调用函数：显示GEI图
def show_img():
    def A():
        img_path = content_entry.get()
        img_path = img_path.replace('\\', '/')  # 反斜杠转为斜杠，可适用于linux系统
        img_name = img_path.split('/')[-1]  # 001_nm-01_000.png
        if os.path.exists(img_path) is False:
            msgbox.showwarning('错误', '图片路径不正确，请再次输入')
        else:
            show_image(img_path, title_name=img_name, equal_scale_to=384)

    T = threading.Thread(target=A)
    T.start()


def transforms():
    def A():
        global y_pred
        img_path = content_entry.get()  # 获取待预测行人的图片的路径
        img_path = img_path.replace('\\', '/')  # 反斜杠转为斜杠，可适用于linux系统
        y_pred_prob, y_pred, y_true, acc = evaluate(img_path)  # 预测行人
        probLabel.configure(text='%.4f' % np.squeeze(y_pred_prob)[y_pred])  # 更新probLabel
        if y_pred == y_true:
            numLabel.configure(text=str(y_pred), fg="green")  # 更新numLabel
            msgbox.showinfo('完成', '步态识别已完成，预测正确！预测的行人标签为:%s' % y_pred)
        else:
            numLabel.configure(text=str(y_pred), fg="red")  # 更新numLabel
            msgbox.showwarning('完成', '步态识别已完成，预测错误！预测的行人标签为:%s，但真实标签为:%s' % (y_pred, y_true))

    T = threading.Thread(target=A)
    T.start()


# 按键调用函数：显示输出结果图
def show_result_images():  # 图片为(b,h,center,c)的uint8类型

    try:
        global y_pred
        msgbox.showinfo('完成', '识别已完成，预测为"%s"' % y_pred)
        show_img()
    except:
        msgbox.showwarning('错误', '请先识别，再显示结果')


# 定义参数（调参只需要改这里即可，其他地方不用改）
n_class = 124  # 类别数
img_path = r'./GEI/001_bg-02_000.png'  # 输入需要识别的图片的路径
h, w, c = 64, 64, 1  # 数据集图片的宽和高和通道
root_h, root_w = 380, 500  # 界面的大小
# 排除一些BUG
img_path = img_path.replace('\\', '/')  # 反斜杠转为斜杠，可适用于linux系统
img_name = img_path.split('/')[-1]  # 001_nm-01_000.png
# -----------------------------------------------GUI界面部分-----------------------------------------------
# 创建GUI总界面
root = tk.Tk()
root.geometry('%sx%s+100+200' % (root_w, root_h))  # 窗口大小
root.title('步态识别系统')  # 窗口标题
# 设置背景图
canvas = tk.Canvas(root, width=root_w, height=root_h, bd=0, highlightthickness=0)
bg_imgpath = 'background.jpg'
bg_img = Image.open(bg_imgpath).resize((root_w, root_h))
bg_photo = ImageTk.PhotoImage(bg_img)
canvas.create_image(root_w // 2, root_h // 2, image=bg_photo)
canvas.place(x=0, y=0)
# 创建容器
fm1 = tk.Frame(root)
fm2 = tk.Frame(root)
fm3 = tk.Frame(root)
fm4 = tk.Frame(root)
fm5 = tk.Frame(root)
# 标签
label1 = tk.Label(fm1, text='待预测行人的GEI图片路径: ', justify=tk.RIGHT)
# 创建打开文件夹的按键
file_img = Image.open(r'file.jpg').resize((16, 16))  # 界面显示打开文件夹的贴图
file_img = ImageTk.PhotoImage(file_img)
button1 = tk.Button(fm1, image=file_img, command=import_content_path)
# 打开文件夹的框，获取数据路径用
content_path_val = tk.StringVar(fm1, value=img_path)
content_entry = tk.Entry(fm1, textvariable=content_path_val, width=40)
# 识别结果显示在界面上
pilImage = Image.open(img_path).resize((128, 128))  # 把图片放上去
tkImage = ImageTk.PhotoImage(image=pilImage)
label2 = tk.Label(fm2, image=tkImage)
# 经过网络模型，进行转换
recognition_button = tk.Button(fm3, text='进行识别', command=transforms, cursor='hand2')
# 查看结果
y_true = int(img_name[0:img_name.find('_')]) - 1  # 第0个label表示第1个人
label3 = tk.Label(fm4, text='真实标签:', font=("黑体", 15, "bold"))
label3_num = tk.Label(fm4, text=str(y_true), font=("黑体", 15, "bold"), fg="green")
label4 = tk.Label(fm5, text='概率:', font=("黑体", 15, "bold"))
probLabel = tk.Label(fm5, text='', font=("黑体", 11, "bold"))
label5 = tk.Label(fm5, text='预测标签:', font=("黑体", 15, "bold"))
numLabel = tk.Label(fm5, text='', relief='groove', fg="red", font=("黑体", 15, "bold"))

# ----------------------------------放置所有组件----------------------------------
# 放置容器1的组件
label1.pack(side='left', anchor='center', expand=True)
content_entry.pack(side='left', anchor='center', expand=True)
button1.pack(side='left', anchor='center', expand=True)
# watch_button1.pack(side='left', anchor='center', expand=True)
fm1.pack(side='top', anchor='center', expand=True)
# 放置容器2的组件
label2.pack(side='left', anchor='center', expand=True)
fm2.pack(side='top', anchor='center', expand=True)
#  放置容器3的组件 识别按键
recognition_button.pack(side='top', anchor='center', expand=True)
fm3.pack(side='top', anchor='center', expand=True)
# 放置容器4的组件 查看结果组件
label3.pack(side='left', anchor='center')
label3_num.pack(side='left', anchor='center')
fm4.pack(side='top', anchor='center', expand=True)
# 放置容器5的组件
label4.pack(side='left', anchor='center')
probLabel.pack(side='left', anchor='center')
label5.pack(side='left', anchor='center')
numLabel.pack(side='left', anchor='center')
fm5.pack(side='top', anchor='center', expand=True)
root.mainloop()

#load_datasets.py
import os

import cv2 as cv
import numpy as np

'''
数据集使用CASIA-B：共124人，有3种行走状态：正常nm-01~nm-06  带背包bg-01~bg-02 穿大衣cl-01~cl-02，共10个。每个行走状态又有11个视角
'''


def load_dataset(dir_path=r'.\GEI', ID=(0, 124)):  # 这里是加载数据集，默认124人全部加载
    x_train_list, x_test_list, y_train_list, y_test_list = [], [], [], []
    image_names = os.listdir(dir_path)
    for image_name in image_names:
        image = cv.imread(os.path.join(dir_path, image_name), flags=0)#以灰图的形式读入
        image=image[:,:,np.newaxis]
        label = int(image_name[0:image_name.find('_')]) - 1  # 第0 label表示第1个人
        index = image_name[0:3]
        condition = image_name[4:9]  # 找出nm-01这些
        angle = image_name[10:13]

        # 以下是训练集和预测集，是通过行走条件划分的, 可根据自己需要修改(保证训练集和测试集没有重复就都是对的)
        if ID[0] <= int(index) <= ID[1]:  # 注释的是常用的训练方式，解注释即可使用(小白提示：#号就是注释，删掉#号就是解注释，解注释后原本的那行需要加回注释)
            # 训练集
            #if condition == 'nm-01' or condition == 'nm-02' or condition == 'nm-03' or condition == 'nm-04':  # 仿照这种写法即可自己改
            if condition == 'nm-01' or condition == 'nm-02' or condition == 'nm-03' or condition == 'nm-04' or condition == 'bg-01' or condition == 'cl-01':
            #if condition == 'nm-01' or condition == 'nm-02' or condition == 'nm-03' or condition == 'nm-04':
            #if condition == 'nm-01' or condition == 'nm-02' or condition == 'nm-03' or condition == 'nm-04':
            #if condition == 'bg-01':
            #if condition == 'cl-01':
                x_train_list.append(image)
                y_train_list.append(label)
            # 测试集
            #if condition == 'nm-05' or condition == 'nm-06':
            if condition == 'nm-05' or condition == 'nm-06' or condition == 'bg-02' or condition == 'cl-02':
            #if condition == 'bg-01' or condition == 'bg-02':
            #if condition == 'cl-01' or condition == 'cl-02':
            #if condition == 'bg-02':
            #if condition == 'cl-02':
                x_test_list.append(image)
                y_test_list.append(label)
    return [np.array(x_train_list), np.array(y_train_list), np.array(x_test_list), np.array(y_test_list)]


def main():
    load_dataset()


if __name__ == '__main__':
    main()


#network.py
import numpy as np
import torch
import torch.nn as nn


# 该py文件就是整个步态识别的算法部分，也叫神经网络模型
# 整个神经网络总结为两层'卷积+激活函数+池化'。在卷积和池化之间加入标准化，使得数据值范围在0-1之间易于被模型训练，在最后使用随机丢弃层降低过拟合，提升模型准确率

class NetWork(nn.Module):  # 网络参数都是超参数，本网络由DK数据工作室调参多次，类似VGG的结构，几乎能使得所有的训练方式都能达到最高的准确率
    def __init__(self, c, h, w, n_class):
        super(NetWork, self).__init__()
        self.c, self.h, self.w, self.n_class = c, h, w, n_class
        # Conv2D的参数in_channels是输入的通道数，out_channels是卷积核的个数(也是输出通道数)，kernel_size是卷积核的大小，strides是每次卷积的步长，padding是是否进行边界填充
        self.conv1 = nn.Conv2d(in_channels=self.c, out_channels=4, kernel_size=3, stride=1, padding=1)
        # BatchNorm2d的参数num_features是输入的通道数，和上面的in_channels参数一个意思
        self.bn1 = nn.BatchNorm2d(num_features=4)  # 批归一化层，把每个批次batch的数据都进行归一化，作用是防止过拟合，增加准确率
        self.relu = nn.ReLU()  # 激活函数使用最常用的relu函数
        self.maxpooling2d = nn.MaxPool2d(kernel_size=2, stride=2)  # 最大池化层，使得特征图的宽和高都会除以2，作用是提取出更重要的特征，不重要的特征直接丢弃
        self.dropout2d = nn.Dropout2d(0.3)  # 改进的Dropout层，作用是更好地防止过拟合，提升准确率

        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1)
        self.bn2 = nn.BatchNorm2d(num_features=8)

        self.flatten = nn.Flatten()  # 把宽高和通道打平成一起  -->  (b,c*h*w)
        self.linear = nn.Linear(in_features=int(np.prod([self.h // 4, self.w // 4, 8])), out_features=self.n_class)

    def forward(self, inputs):  # 整个神经网络总结为两层'卷积+激活函数+池化'。在卷积和池化之间加入标准化层，使得数据值范围在0-1之间易于被模型训练，在最后使用随机丢弃层降低过拟合，提升模型准确率
        # 第一层
        x = self.conv1(inputs)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpooling2d(x)
        x = self.dropout2d(x)
        # 第二层
        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu(x)
        x = self.maxpooling2d(x)
        x = self.dropout2d(x)
        # 对特征进行打平成向量，然后使用全连接层进行分类输出
        x = self.flatten(x)  # 打平层
        x = self.linear(x)  # 全连接层，也是输出层
        return x


def main():  # 这里是起到调试神经网络的作用
    b = 128  # batch_size，是指一次输入多少张GEI能量图到网络里
    c, h, w, n_class = 1, 64, 64, 124
    x = torch.ones([b, c, h, w])
    model = NetWork(c, h, w, n_class)
    print(model(x).shape)


if __name__ == '__main__':
    main()
#test.py
import time

import numpy as np
import os
import torch

from load_datasets import load_dataset
from network import NetWork

'''
这里是测试整个测试集的准确率。输入每个人的GEI图，输出各自的每个类别的概率，然后选出概率最大的类别作为识别的类别
数据集使用CASIA-B：共124人，有3种行走状态：正常nm-01~nm-06  带背包bg-01~bg-02 穿大衣cl-01~cl-02，共10个。每个行走状态又有11个视角
'''
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # 可排除一些bug
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 显卡能用于深度学习，就会使用，用不了则自动使用CPU运行

# 定义参数
n_class = 124  # 共几类
save_model_name = 'model.h5'  # 模型保存的名字
# 加载测试集
_, _, x_test, y_test = load_dataset(
    ID=(1, 124))  # 这里默认是预测整个数据集124个人。ID是从1开始编号的，如果需要测试第1个人，就改成ID=(1, 1)。测试第2个人，就改成ID=(2, 2)
b, h, w, c = x_test.shape
x_test = np.transpose(x_test, axes=[0, 3, 1, 2]).astype('float32') / 255.  # 转置和归一化
print(x_test.shape, y_test.shape)
model = NetWork(c, h, w, n_class).to(device)  # 加载网络(调用network.py文件里的network函数)
try:  # 尝试载入模型
    model.load_state_dict(torch.load(save_model_name, map_location=device))
    print('载入训练好的模型的权重')
except:
    print('模型权重未载入，权重和网络不匹配！请重新训练！')
model.eval()
t = time.time()
y_pred = model(torch.from_numpy(x_test).to(device)).cpu().detach().numpy()  # 预测
y_pred = np.argmax(y_pred, -1)
print('预测值:', y_pred.tolist())  # 列表里的每个数值，就是行人的编号，范围从0开始数，到123，共124人。预测和真实值的编号对上，说明预测对了，否则就是预测错了
print('真实值:', y_test.tolist())
print('test_acc:', np.mean(np.equal(y_pred, y_test)), '耗时:%s秒' % (time.time() - t))  # 这个准确率就是结果，表示预测对的人，占总人数的比例
#train.py
import os

import numpy as np
import torch
import torch.nn as nn
from matplotlib import pyplot as plt

from load_datasets import load_dataset
from network import NetWork

print('pytorch版本:', torch.__version__)
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'  # 可排除一些bug

# ---------------------------------DK数据工作室：基于深度学习的步态识别---------------------------------
'''
数据集使用CASIA-B：这里下载：http://www.cbsr.ia.ac.cn/china/Gait%20Databases%20CH.asp  。找到“DataSet B”，点击下载
共124人，有3种行走状态：正常nm-01~nm-06  带背包bg-01~bg-02 穿大衣cl-01~cl-02，共10个。每个行走状态又有11个视角

我们的博客配置教程：https://blog.csdn.net/weixin_45941288/article/details/123428784?spm=1001.2014.3001.5501
之前的环境，建议卸了，以免出错，错了又要重来！然后跟着我们教程配置就行，至今没试过有失败的案例

本代码构造简单，技术已经对其优化，适合小白入门步态识别领域。如果后续有其他需要制作的，欢迎继续联系我们，我们致力于做出更高质量的代码
'''


# 画图
def draw_loss_acc(history):
    fig = plt.figure(figsize=(10, 7))
    ax1 = plt.subplot(2, 1, 1)
    plt.title('loss and val_loss')
    plt.plot(history.get('epoch'), history.get('loss'), label='loss', color='g')  # 这是训练时的损失函数
    plt.plot(history.get('epoch'), history.get('val_loss'), label='val_loss', color='r')  # 这是测试时的损失函数
    for i in range(len(history.get('epoch'))):
        if i % 20 == 0:
            plt.annotate('(%d,%.2f)' % (history.get('epoch')[i], history.get('loss')[i]),
                         xy=(history.get('epoch')[i], history.get('loss')[i]))
            plt.annotate('(%d,%.2f)' % (history.get('epoch')[i], history.get('val_loss')[i]),
                         xy=(history.get('epoch')[i], history.get('val_loss')[i]))
    plt.legend()

    ax2 = plt.subplot(2, 1, 2)
    plt.title('accuracy and val_accuracy')
    plt.plot(history.get('epoch'), history.get('accuracy'), label='accuracy', color='g')  # 这是训练时的准确率
    plt.plot(history.get('epoch'), history.get('val_accuracy'), label='val_accuracy', color='r')  # 这是测试时的准确率
    for i in range(len(history.get('epoch'))):
        if i % 20 == 0:
            plt.annotate('(%d,%.2f)' % (history.get('epoch')[i], history.get('accuracy')[i]),
                         xy=(history.get('epoch')[i], history.get('accuracy')[i]))
            plt.annotate('(%d,%.2f)' % (history.get('epoch')[i], history.get('val_accuracy')[i]),
                         xy=(history.get('epoch')[i], history.get('val_accuracy')[i]))
    plt.legend()
    plt.show()


device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 显卡能用于深度学习，就会使用，用不了则自动使用CPU运行

# 1、定义参数
epochs = 100  # 训练几轮，也叫迭代次数或训练次数
batch_size = 128  # 每轮每批输入的个数
n_class = 124  # 共几类
save_model_name = 'model.h5'  # 模型保存的名字
# 2、加载数据集中的训练集和测试集(需要测试集是为观察损失函数和准确率，防止过拟合等)
x_train, y_train, x_test, y_test = load_dataset(ID=(1, 124))  # 获取训练集的x和y和测试集的x和y。x是GEI图，y是标签
x_train = np.transpose(x_train, axes=[0, 3, 1, 2]).astype('float32') / 255.  # 转置和归一化
x_test = np.transpose(x_test, axes=[0, 3, 1, 2]).astype('float32') / 255.
x_train, y_train, x_test, y_test = torch.tensor(x_train), torch.tensor(y_train), torch.tensor(x_test), torch.tensor(
    y_test)
b, c, h, w = x_train.shape
print(x_train.shape, y_train.shape, x_test.shape, y_test.shape, y_train.dtype)
torch_train_dataset = torch.utils.data.TensorDataset(x_train, y_train.long())
torch_test_dataset = torch.utils.data.TensorDataset(x_test, y_test.long())
train_loader = torch.utils.data.DataLoader(dataset=torch_train_dataset, batch_size=batch_size,
                                           shuffle=True)
test_loader = torch.utils.data.DataLoader(dataset=torch_test_dataset, batch_size=batch_size,
                                          shuffle=False)

a = next(iter(train_loader))
print(a[0].shape, a[1].shape)

# 搭建网络
model = NetWork(c, h, w, n_class).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # 定义优化器
# 训练
try:  # 尝试载入模型，可断点续训
    model.load_state_dict(torch.load(save_model_name, map_location=device))
    print('已加载上次的权重，如需从0开始训练，请删除.h5文件再试\n断点续训中......')
except:
    print('模型未载入，权重和网络不匹配！正在重新训练中......')
    pass
history = {'epoch': [], 'loss': [], 'val_loss': [], 'accuracy': [], 'val_accuracy': []}
for epoch in range(epochs):
    # 训练
    model.train()
    train_correct = 0
    train_total = 0
    train_total_loss = 0.
    for i, (x, y) in enumerate(train_loader):
        x = x.to(device)  # (b,c,h,w)
        y = y.to(device)  # (b,)
        logits = model(x)  # (b,n_class)
        train_loss = nn.CrossEntropyLoss()(logits, y)  # 使用多分类交叉熵损失函数， y不需要onehot编码！！
        # print('loss:', loss, loss.shape)
        # train_loss = train_loss.mean()
        train_total_loss += train_loss.item()
        train_total += y.size(0)
        _, y_pred = torch.max(logits, dim=1)
        train_correct += (y_pred == y).sum().item()
        # 梯度归0反向传播
        optimizer.zero_grad()
        train_loss.backward()
        optimizer.step()
        # print('loss:', loss.item())
    # 测试
    model.eval()
    with torch.no_grad():
        test_correct = 0
        test_total = 0
        test_total_loss = 0.
        for i_test, (x, y) in enumerate(test_loader):
            x = x.to(device)
            y = y.to(device)
            logits = model(x)
            test_loss = nn.CrossEntropyLoss()(logits, y)
            test_total_loss += test_loss.item()
            _, y_pred = torch.max(logits, dim=1)
            test_total += y.size(0)
            test_correct += (y_pred == y).sum().item()

    # 记录训练损失函数loss和准确率accuracy，以及测试损失函数val_loss和准确率val_accuracy
    loss = train_total_loss / (i + 1)
    val_loss = test_total_loss / (i_test + 1)
    accuracy = train_correct / train_total
    val_accuracy = test_correct / test_total
    history['loss'].append(np.array(loss))  # 训练集损失函数
    history['val_loss'].append(np.array(val_loss))  # 测试集损失函数
    history['accuracy'].append(np.array(accuracy))  # 训练集准确率
    history['val_accuracy'].append(np.array(val_accuracy))  # 测试集准确率
    history['epoch'].append(epoch)  # 训练次数
    print('epochs:%s/%s:' % (epoch + 1, epochs),
          'loss:%.6f' % history['loss'][epoch], 'accuracy:%.6f' % history['accuracy'][epoch],
          'val_loss:%.6f' % history['val_loss'][epoch], 'val_accuracy:%.6f' % history['val_accuracy'][epoch])
# 保存模型
print('已保存模型到:%s' % save_model_name)
torch.save(model.state_dict(), save_model_name)
draw_loss_acc(history)
#utils.py
import cv2 as cv
import numpy as np
# from torchvision.transforms import Resize

global k2
k2 = None


def cv_imread(img_path):  # 该函数用于支持输入中文的路径
    '''
    输入图片路径，输出(h,w,3)的BGR图片。BGRA图片会自动转为BGR（只能读图片，可支持中文路径）
    '''
    img = cv.imdecode(np.fromfile(img_path, dtype=np.uint8), -1)  # 可支持中文路径
    if img.shape[-1] >= 4:
        img = cv.cvtColor(img, cv.COLOR_BGRA2BGR)  # 32位深BGRA图片转为24位BGR图
    return img


def show_image(image_or_image_path, title_name='image', equal_scale_to=None):  # 该函数用于显示图片
    '''

    :param image_or_image_path: 图片或路径，图片是(h,w,c)的uint8
    :param title_name: 图片窗口名字
    :param equal_scale_to: 等比缩放为
    :return: 无
    '''
    if isinstance(image_or_image_path, str):
        image = cv_imread(image_or_image_path)
    else:
        image = image_or_image_path
    image = resize_image(image[np.newaxis, ...], equal_scale_to=equal_scale_to)
    image = np.array(image)[0]
    # print('image', image.shape, image.dtype, image.max(), image.min())
    image = image.astype('uint8')
    cv.imshow(title_name, image)
    cv.waitKey()
    cv.destroyAllWindows()


def resize_image(images, equal_scale_to=512):  # 该函数用于缩放图片到固定尺寸
    '''
    images为(b,h,w,c)，输出改变形状后的images
    equal_scale_to为None时不改变size
    '''
    if equal_scale_to is not None:
        # images = Resize(size=(equal_scale_to, equal_scale_to))(images)
        image_list = []
        for image in images:
            image = cv.resize(image, dsize=(equal_scale_to, equal_scale_to))
            image_list.append(image)
        images = np.array(image_list)
    return images


# 从视频里截图
def screenshot_from_camera(save_name='image'):  # 按s截图，或者点击鼠标左键截图
    '''
    读视频
    :param normalize=False输出0-255的uint8；normalize=True输出0-1的float32
    :return: images, fps
    '''
    # cv.namedWindow('screenshot_from_camera')
    global k2
    capture = cv.VideoCapture(0, cv.CAP_DSHOW)  # 参数为0表示打开摄像头
    i = 0
    while 1:
        ret, frame = capture.read()
        if ret is False:
            break
        frame = cv.flip(frame, 1)
        cv.imshow('frame', frame)
        k1 = cv.waitKey(1)  # 每帧数据延时 1ms，延时不能为 0，否则读取的结果会是静态帧
        cv.setMouseCallback('frame', on_mouse)
        if k1 == ord('s') or k2 == ord('s'):  # 若检测到按键 ‘s’，或鼠标左键点击，则截图
            i += 1
            save_path = r'%s_%s.jpg' % (save_name, i)
            cv.imwrite(save_path, frame)
            print(r'截图已完成，已保存为:%s' % save_path)
            k2 = None
        if k1 == ord('q') or k2 == ord('q'):
            k2 = None
            break
    capture.release()
    cv.destroyAllWindows()


def on_mouse(event, x, y, flags, param):  # 鼠标点击事件
    global k2
    if event == cv.EVENT_LBUTTONDOWN:  # 鼠标左键，运行此函数
        k2 = ord('s')
    if event == cv.EVENT_RBUTTONDOWN:  # 鼠标右键，运行此函数
        k2 = ord('q')
